---
title: "STAT 5361 -  HW 8"
author: Patrick Toman^[<patrick.toman@uconn.edu>; Ph.D. student at Department of Statistics,
  University of Connecticut.]
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = F)
```


# Problem 7.5.1

## Part A

```{r,importance_sampling}

fx <- function(x){
  
  (5*sqrt(2*pi))^(-1)*(x^2)*exp(-((x-2)^2)/2)
  
}

hx <- function(x){
  
  x^2

}

gx <- function(x){
  
  (sqrt(2*pi)^(-1))*exp(-(x^2)/2)
  
  
}


importance_sampler <- function(sample_size,seed_set=1113){
  
  set.seed(seed_set)
  
  do_1sim <- function(x){
    
    xi <- rnorm(x,mean = 0,sd=1)
    
    wxi <- fx(xi)/gx(xi)
    
    hxi <- hx(xi)
    
    hxi*wxi
    
  }
  
  
  sim_results <- replicate(sample_size,do_1sim(1))
  
  mu_hat <- mean(sim_results)
  
  var_hat <- var(sim_results)
  
  par_est <- cbind.data.frame('mu_est'= mu_hat,'var_est' = var_hat )
  
  
  return(list('par_est_df'= par_est,'sim'= sim_results))
}


sample_size <- c(1e3,1e4,5e4)

test <- lapply(sample_size, importance_sampler)



test[[3]]$par_est_df

```

## Part B


An improved choice for $g(x)$ would be  $g(x) \sim N(2,1)$

### Proof 

Suppose we have the following 

- $f(x) = \frac{1}{5\sqrt{2\pi}}x^2 e^{-\frac{(x-2)^2}{2}} , -\infty < x < \infty$
- $g(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{(x-2)^2}{2}}, -\infty < x < \infty$

Then we derive the \textit{importance} ratio as 

\begin{align*}
  w(x) & = \frac{f(x)}{g(x)} \\
       & = \frac{\frac{1}{5\sqrt{2\pi}}x^2 e^{-\frac{(x-2)^2}{2}}}{\frac{1}{\sqrt{2\pi}}e^{-\frac{(x-2)^2}{2}}} , -\infty < x < \infty \\
       & = \frac{x^2}{5} 
\end{align*}

Clearly, we satisfy the condition that when $f(x) > 0$ then $g(x) > 0$ since we have $f(x),g(x) > 0 , \forall x \ \in (-\infty,\infty)$. Furthermore, using $g(x) \sim N(2,1)$ has made $g(x)$ much more proportional to $h(x)f(x)$, thus we should now have a vastly improved importance sampler to evaluate $E[h(x)]$. 

## Part C

### Implementation 

We re-implement our importance sampler using $g(x) \sim N(2,1)$ as our new density.


```{r,importance_sampler_improved}


gx_2 <- function(x){
  
  (sqrt(2*pi)^(-1))*exp(-((x-2)^2)/2)
  
  
}

is_improved <- function(sample_size,seed_set=1113){
  
  set.seed(seed_set)
  
  do_1sim <- function(x){
    
    xi <- rnorm(x,mean = 2,sd=1)
    
    wxi <- fx(xi)/gx_2(xi)
    
    hxi <- hx(xi)
    
    hxi*wxi
    
  }
  
  
  sim_results <- replicate(sample_size,do_1sim(1))
  
  mu_hat <- mean(sim_results)
  
  var_hat <- var(sim_results)
  
  par_est <- cbind.data.frame('mu_est'= mu_hat,'var_est' = var_hat )
  
  
  return(list('par_est_df'= par_est,'sim'= sim_results))
}

test_2 <- lapply(sample_size, is_improved)

results_2 <- rbind.data.frame(test_2[[1]]$par_est_df,
                              test_2[[2]]$par_est_df,
                              test_2[[3]]$par_est_df)
results_2 <- cbind.data.frame('n'=sample_size,results_2)
```


## Part D

Clearly, we can see that our new importance sampler with $g(x) \sim N(2,1)$ has greatly improved. Note that for all three sample sizes $N \in \{1000,10000,50000\}$ the estimate $\hat{\mu}$ are quite similar with estimates falling approximately around $8.5$. Furthermore, $Var(\hat{\mu})$ has stabilized dramatically in comparison to the original sampler with values ranging from $\approx 159$ to $\approx 212$.

```{r,new_results,echo=F}
knitr::kable(results_2)

```


# Problem 7.5.2 

## Part A 

Suppose we have the following 

- $S(0)=1$
- $r = 0.05$
- $n=12$

Then we can simulate paths from the geometric brownian motion 

$$\frac{d S(t)}{S(t)} = r dt + \sigma dW(t)$$

using the random walk construction which has steps 

1. Set or sample $X(0)$
2. sample $Z_1,...,Z_n \overset{iid}{\sim} N(0,1)$
3. For $i \in \{0,1,\ldots,n-1\}$ compute $D_i = X(t_{i+1}) - X(t_i)$ and set $X(t_{i+1}) = X(t_i) + D_i$
4. Return $X(0),X(1),\ldots,X(t_n)$

An implementation of this algorithm is given below. 

```{r,brownian_sim}
library(tidyverse)


brownian_sim <- function(s0,r,sigma,end,n){
  
  dt <- end/n
  
  t <- seq(0,end,by=dt)
  
  X <- c(s0,r*dt+sigma*sqrt(dt)*rnorm(n,mean=0,sd=1))
  
  Xt <- cumsum(X)
  
  return(Xt)
  
  
}


```

## Part (B)

```{r,sfunctions,echo=FALSE}

sT <- function(r,end,s0=1,sigma){
  
  s0*exp(r - 1/2*(sigma^2))*end + sigma*sqrt(end)*rnorm(1)
  
}

sA <- function(path){
  
  mean(path)
  
  
  
} 

sG <- function(path){
  
  exp(mean(log(path)))
  
}


pA <- function(r,end,path,K){
  
  exp(-r*end)*max(sA(path=path)-K,0)
  
}

pE <- function(r,end,sigma,K){
  
  exp(-r*end)*max(sT(r=r,end=end,sigma=sigma)-K,0)
  
}

pG <- function(r,end,sigma,K){
  
  exp(-r)*max(sG(path)-K,0)
  
}


r <- 0.05

sigma <- 0.5  

end <- 1 # T

n <- 12 

s0 <- 1

n_sims <- 5000

K_seq <- seq(1.1,1.5,by=.1)

brownian_test <- replicate(n_sims,brownian_sim(s0=s0,r=r,sigma=sigma,end=end,n=n),simplify = F)

names(brownian_test) <- paste0('P',1:length(brownian_test))

#############################################################################################################################
# Corr(PA,ST)
#############################################################################################################################

pA_sim_list <- list()

for(i in 1:length(K_seq)){
  
  pA_tmp <- c()
  
  for(j in 1:n_sims){
    
    pA_tmp[j] <- pA(r=0.05,end = 1,path=brownian_test[[j]],K=K_seq[i])
    
    
  }
  
  pA_sim_list[[i]] <- pA_tmp
  
}


sT_sim <- replicate(n_sims,sT(r=r,end = 1,s0=1,sigma = sigma))

pa_st_cov <- c()

for(k in 1:length(K_seq)){
  
  pa_st_cov[k] <- cor(unlist(pA_sim_list[[k]]),sT_sim)
  
  
}

#############################################################################################################################
#############################################################################################################################


```